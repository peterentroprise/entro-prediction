version: '3'
services:
  haystack-api:
    build:
      context: .
      dockerfile: Dockerfile
    image: "deepset/haystack-cpu:latest"
    ports:
      - 8000:8000
    volumes:
      # Optional: mount your own models from disk into the container
      - "./models:/home/user/models"
    environment:
      # See rest_api/config.py for more variables that you can configure here.
      - DB_HOST=35.188.203.27
      - DB_PORT=9200
      - DB_USER=elastic
      - DB_PW=qt5hfjmkmxtvlf4pw6qhlk6b
      - USE_GPU=False
      # Load a model from transformers' model hub or a local path into the FARMReader.
      - READER_MODEL_PATH=deepset/roberta-base-squad2
      # - READER_MODEL_PATH=home/user/models/roberta-base-squad2
      # Alternative: If you want to use the TransformersReader (e.g. for loading a local model in transformers format):
      # - READER_TYPE=TransformersReader
      # - READER_MODEL_PATH=/home/user/models/roberta-base-squad2
      # - READER_TOKENIZER=/home/user/models/roberta-base-squad2
    restart: always
    command: "/bin/bash -c 'sleep 15 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 1 --timeout 180'"